# プロンプトエンジニアリング

## 概要

ChatGPTなどの生成AIに使われているLLM（大規模言語モデル）を効率的に使いこなすために必要な「プロンプト（言語モデルへの指示）」を開発、最適化するための学問分野を指す。

## 手段

効率的な回答を得るにはいくつか手段がある。

* LLMの設定を変更する \
いくつかのパラメータを変更して、LLMからの回答を変化させる。
  * Temperature \
  ランダム性の増減。詩の生成やその他の創造的なタスクでは、この数値を上げると効果的かも。
  * Top_p \
   正確で事実に基づいた回答を求めるか、多様な回答を求めるかを設定する。

* プロンプトを改善する
  * 基本 \
    以下のテクニックを順に使用する。
    * Zero-Shotプロンプティング
    * Few-Shotプロンプティング
    * Chain-of-Thoughtプロンプティング
  * 応用 \
  　基本のテクニックを使った後にさらに回答の精度を上げる方法。
    * Self-Consistency（自己整合性）
    * 知識生成プロンプティング
    * Prompt Chaining
    * Tree of Thoughts
    * その他

## 基本テクニック
* Zero-Shotプロンプティング \
任意の例など事前に情報を提供せずに質問を直接提示するプロンプトです。 \
![Zero-Shotプロンプティング](image\Zero-Shotプロンプティング.bmp)
ここで期待する回答が得られない場合はFew-Shotプロンプティングに移行する。

* Few-Shotプロンプティング \
いくつかの例を提示するプロンプトです。 \
![Few-Shotプロンプティング](image\Few-Shotプロンプティング.png) \
ただし、この質問が複雑化すると期待する答えを得られなくなります。以下は計算が合っているけど41を偶数と判定しいている。
![Few-Shotプロンプティング](image\Few-Shotプロンプティング_NG.bmp) \
そこで、より複雑な算術、常識、および象徴的推論タスクに対応するために、Chain-of-Thought (CoT) promptingが普及しています。

* Chain-of-Thoughtプロンプティング \
推論ステップを提示することによって、より複雑なタスクを回答できるようにするプロンプトです。 \
![CoTプロンプティング](image\Chain-of-Thoughtプロンプティング.bmp)

## 応用テクニック
* Self-Consistency（自己整合性）\
推論ステップを含めた大量のQ&Aを与えた後に目的の質問を投げて回答させる手法。
* 知識生成プロンプティング \
質問に加えていくつかの前提の知識を渡したうえで、その知識を参考にして回答させる手法。
* Prompt Chaining \
最初のプロンプトでモデルに広いコンセプトを理解させ、その後のプロンプトで特定の詳細や文脈を尋ねることで、より具体的でニュアンス豊かな回答を引き出す手法。
* その他
  * Tree of Thoughts
  * Retrieval Augmented Generation (RAG)
  * Automatic Reasoning and Tool-use (ART)
  * 自動プロンプトエンジニア（APE）
  * ほかいろいろ

## 参考リンク

[Prompt Engineering Guide](https://www.promptingguide.ai/jp)
